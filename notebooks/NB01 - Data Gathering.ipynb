{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering\n",
    "\n",
    "**Name: Smyan Kapoor**\n",
    "\n",
    "**Candidate Number: 36745**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: system-ui; color: #000000; padding: 20px 30px 20px 20px; background-color: #FFFFFF; border-left: 8px solid #2B7A78; border-radius: 8px; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1); max-width:700px\">\n",
    "\n",
    "**Notebook Overview:** In this stage, we fetch and structure Reddit data through the API in a secure and reproducible way, setting the foundation for subsequent analysis.\n",
    "\n",
    "#### Methodology\n",
    "\n",
    "- **Subreddit Selection:** We will target 3–5 subreddits that are most relevant to the question: *How has retail investor activity changed in the recent days of market ucncertainty under the Trump Administration?*\n",
    "- **API Access:** Use the `requests` library to access Reddit's API with proper authentication, ensuring all API credentials are securely hidden from version control.\n",
    "- **Data Extraction:**\n",
    "  - Retrieve submission and comment data via authenticated requests.\n",
    "  - Extract and normalize JSON structures into clean tabular format using `pandas` techniques.\n",
    "- **Database Integration:**\n",
    "  - Dump the processed data into an **SQLite database**, mapping each dataframe to its corresponding table.\n",
    "  - Ensure proper **relational mapping** between the tables for efficient querying and integrity.\n",
    "- **Output:** The structured and linked data will be ready for access in downstream notebooks for analysis and visualisation.\n",
    "\n",
    "- **This pipeline ensures authenticated, secure, and well-structured data collection, ready for deeper exploration.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ⚙️ Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# this is stored in a utils.py within the notebooks folder\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subreddit Selection  \n",
    "\n",
    "   A simple google search (Reddit) reveals that some of the biggest investing subreddits by subscribers at the time of writing are r/wallstreetbets (18M), r/investing (3M), r/stocks (8.5M) and r/stockmarket(3.5M). These should be sufficient to look at when we measure investor sentiment. We operate under the assumption that a negligible amount of institutional investor activity is present in these subreddits as more experienced investors have access to more sophisticated tools and circles for investment guidance. We will choose to preclude the subreddits that focus more on trading and techincal analysis such as r/trading as those have greater focus on how to trade and other educational aspects compared to our selected subreddits. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Securing Credentials\n",
    "\n",
    "Using the `python-dotenv` library and a ```.env``` file in the root directory, into which we add our credentials, specifically \n",
    "\n",
    "```plaintext\n",
    "REDDIT_USERNAME=your_username\n",
    "REDDIT_PASSWORD=your_password\n",
    "REDDIT_CLIENT_ID=your_client_id\n",
    "REDDIT_CLIENT_SECRET=your_client_secret\n",
    "```\n",
    "\n",
    "we can then load our credentials safely using the `python-dotenv` library's load function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credentials are now stored in the `os.environ` dictionary, a safe place closer to the Operating System. We can use `os.getenv()` to retrieve the values from the dictionary when passing to the Reddit API without ever looking at them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's send a first request to the API to get an access token. We will pass this string in the headers of all subsequent requests to confirm our identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_auth = requests.auth.HTTPBasicAuth(os.getenv(\"CLIENT_ID\"), os.getenv(\"CLIENT_SECRET\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also send via [HTTP's](https://www.w3schools.com/tags/ref_httpmethods.asp) POST method, our Reddit username and password and identify ourselves using a `User-Agent` header as per Reddit documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data = {\"grant_type\": \"password\", \"username\": os.getenv('REDDIT_USERNAME'), \"password\": os.getenv('REDDIT_PASSWORD')}\n",
    "headers = {\"User-Agent\": f\"LSE DS105W (2024/25) Data Collection by {os.getenv('REDDIT_USERNAME')}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we send the request using a function that returns the reddit access token :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "my_token = get_reddit_access_token(client_auth, post_data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on, all requests need to be followed by these HTTP HEADERS\n",
    "headers = {\"Authorization\": f\"bearer {my_token}\", \"User-Agent\": f\"LSE DS105W (2024/25) API practice by {os.getenv('REDDIT_USERNAME')}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "Extracting data from the Reddit API and turning it into json:\n",
    "\n",
    "+ Using the headers and token we got from the previous step, we can now make authenticated requests to the Reddit API\n",
    "\n",
    "+ We use ```requests.get()``` to fetch the data from the API in three seperate functions which return lists, first for subreddit metadata, next for posts and finally for comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>name</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t5_2qjfk</td>\n",
       "      <td>stocks</td>\n",
       "      <td>8568672</td>\n",
       "      <td>1.214556e+09</td>\n",
       "      <td>The most serious place on Reddit for Stock rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5_2qjuv</td>\n",
       "      <td>StockMarket</td>\n",
       "      <td>3511090</td>\n",
       "      <td>1.215606e+09</td>\n",
       "      <td>Welcome to /r/StockMarket! Our objective is to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>18185653</td>\n",
       "      <td>1.328045e+09</td>\n",
       "      <td>Like 4chan found a Bloomberg Terminal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5_2qhhq</td>\n",
       "      <td>investing</td>\n",
       "      <td>2990760</td>\n",
       "      <td>1.205584e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit_id            name  subscribers   created_utc  \\\n",
       "0     t5_2qjfk          stocks      8568672  1.214556e+09   \n",
       "1     t5_2qjuv     StockMarket      3511090  1.215606e+09   \n",
       "2     t5_2th52  wallstreetbets     18185653  1.328045e+09   \n",
       "3     t5_2qhhq       investing      2990760  1.205584e+09   \n",
       "\n",
       "                                         description  \n",
       "0  The most serious place on Reddit for Stock rel...  \n",
       "1  Welcome to /r/StockMarket! Our objective is to...  \n",
       "2             Like 4chan found a Bloomberg Terminal.  \n",
       "3                                                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise our list of subs\n",
    "subs_list = ['stocks', 'stockmarket', 'wallstreetbets', 'investing']\n",
    "\n",
    "sub_data = fetch_subreddit_info(subs_list, headers)\n",
    "unfiltered_sub_df = pd.DataFrame(sub_data)\n",
    "\n",
    "rename_dict = {'name': 'subreddit_id', 'display_name': 'name', \"public_description\": 'description'}\n",
    "\n",
    "filtered_sub_df = unfiltered_sub_df[[\"name\", \"display_name\", \"subscribers\", \"created_utc\", \"public_description\"]].rename(columns=rename_dict)\n",
    "\n",
    "filtered_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function fetch_recent_posts takes in a list of subreddits and retrieves recent post data using Reddit’s API. It accepts days and max_pages as arguments. Using the time library, it converts the days parameter into a Unix timestamp to filter for posts created within that timeframe.\n",
    "\n",
    "For each subreddit, the outer loop iterates through the list of subreddits, while the inner loop handles pagination. Since Reddit’s API allows a maximum of 100 posts per request (with a cap of 1000 per subreddit), we page through results using the after parameter, which holds the unique ID of the last post from the previous batch. This ensures continuity across pages.\n",
    "\n",
    "Posts are sorted by new to prioritize the most recent content, allowing us to capture fresh data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts fetched: 861 | Last sub accessed: r/stocks\n",
      "Total posts fetched: 1730 | Last sub accessed: r/stockmarket\n",
      "Total posts fetched: 2516 | Last sub accessed: r/wallstreetbets\n",
      "Total posts fetched: 3472 | Last sub accessed: r/investing\n"
     ]
    }
   ],
   "source": [
    "# get our post data \n",
    "posts_list = fetch_recent_posts(subs_list, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the functions above, we find that we get numbers below 1000, for each subreddit despite that being the call limit. However, research reveals that this is because deleted posts are counted in the 1000 post limit, but are not called on. Hence, as long as a post has been deleted within the timeframe we are calling, it will reduce the number of 'live' posts we can request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>media_metadata.7brf4hj4zpne1.s.u</th>\n",
       "      <th>media_metadata.7brf4hj4zpne1.id</th>\n",
       "      <th>media_metadata.w06y0kg3zpne1.status</th>\n",
       "      <th>media_metadata.w06y0kg3zpne1.e</th>\n",
       "      <th>media_metadata.w06y0kg3zpne1.m</th>\n",
       "      <th>media_metadata.w06y0kg3zpne1.p</th>\n",
       "      <th>media_metadata.w06y0kg3zpne1.s.y</th>\n",
       "      <th>media_metadata.w06y0kg3zpne1.s.x</th>\n",
       "      <th>media_metadata.w06y0kg3zpne1.s.u</th>\n",
       "      <th>media_metadata.w06y0kg3zpne1.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>stocks</td>\n",
       "      <td>https://ibb.co/Wv2bD8GZ\\n\\nMarkets have recent...</td>\n",
       "      <td>t2_184gki20bw</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Wait a second. Does this look concerning.</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>stocks</td>\n",
       "      <td>Preparing for the coming recession.  Intereste...</td>\n",
       "      <td>t2_1jmg1yuod1</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Recession sectors/stocks</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>stocks</td>\n",
       "      <td>TSLA car sales came down today(336k vs 386k fr...</td>\n",
       "      <td>t2_172wcish</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Why is TSLA up 5% today?</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>stocks</td>\n",
       "      <td>Amazon has put in a last-minute bid to acquire...</td>\n",
       "      <td>t2_tyx9w</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NYT: Amazon has submitted a last-minute bid to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>stocks</td>\n",
       "      <td>The semiconductor sector sold off simply becau...</td>\n",
       "      <td>t2_qben5ncs</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>The AI trade is far from over.</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>None</td>\n",
       "      <td>investing</td>\n",
       "      <td>Hey everyone,\\n\\nI'm going to preface this by ...</td>\n",
       "      <td>t2_15uocx</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Factors influencing gold bullion and efts?</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>None</td>\n",
       "      <td>investing</td>\n",
       "      <td>I was thinking the other day about what tech s...</td>\n",
       "      <td>t2_5fvrjky</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Top 3 companies to invest forever goog, Micros...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>None</td>\n",
       "      <td>investing</td>\n",
       "      <td>If i sell some stock in my ROTH IRA , whom I p...</td>\n",
       "      <td>t2_51ikddo7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>If i sell stock in ROTH IRA</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>None</td>\n",
       "      <td>investing</td>\n",
       "      <td>Hi everyone, \\n\\nWhat's the major difference b...</td>\n",
       "      <td>t2_3hqti33t</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Broker company question, does it even matter?</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>None</td>\n",
       "      <td>investing</td>\n",
       "      <td>I kept an eye on this ater stock since the las...</td>\n",
       "      <td>t2_1hpcjzd4db</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>ATER STOCK ANY THOUGHTS LOOKS GOOD</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3472 rows × 7700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     approved_at_utc  subreddit  \\\n",
       "0               None     stocks   \n",
       "1               None     stocks   \n",
       "2               None     stocks   \n",
       "3               None     stocks   \n",
       "4               None     stocks   \n",
       "...              ...        ...   \n",
       "3467            None  investing   \n",
       "3468            None  investing   \n",
       "3469            None  investing   \n",
       "3470            None  investing   \n",
       "3471            None  investing   \n",
       "\n",
       "                                               selftext author_fullname  \\\n",
       "0     https://ibb.co/Wv2bD8GZ\\n\\nMarkets have recent...   t2_184gki20bw   \n",
       "1     Preparing for the coming recession.  Intereste...   t2_1jmg1yuod1   \n",
       "2     TSLA car sales came down today(336k vs 386k fr...     t2_172wcish   \n",
       "3     Amazon has put in a last-minute bid to acquire...        t2_tyx9w   \n",
       "4     The semiconductor sector sold off simply becau...     t2_qben5ncs   \n",
       "...                                                 ...             ...   \n",
       "3467  Hey everyone,\\n\\nI'm going to preface this by ...       t2_15uocx   \n",
       "3468  I was thinking the other day about what tech s...      t2_5fvrjky   \n",
       "3469  If i sell some stock in my ROTH IRA , whom I p...     t2_51ikddo7   \n",
       "3470  Hi everyone, \\n\\nWhat's the major difference b...     t2_3hqti33t   \n",
       "3471  I kept an eye on this ater stock since the las...   t2_1hpcjzd4db   \n",
       "\n",
       "      saved mod_reason_title  gilded  clicked  \\\n",
       "0     False             None       0    False   \n",
       "1     False             None       0    False   \n",
       "2     False             None       0    False   \n",
       "3     False             None       0    False   \n",
       "4     False             None       0    False   \n",
       "...     ...              ...     ...      ...   \n",
       "3467  False             None       0    False   \n",
       "3468  False             None       0    False   \n",
       "3469  False             None       0    False   \n",
       "3470  False             None       0    False   \n",
       "3471  False             None       0    False   \n",
       "\n",
       "                                                  title link_flair_richtext  \\\n",
       "0             Wait a second. Does this look concerning.                  []   \n",
       "1                              Recession sectors/stocks                  []   \n",
       "2                              Why is TSLA up 5% today?                  []   \n",
       "3     NYT: Amazon has submitted a last-minute bid to...                  []   \n",
       "4                        The AI trade is far from over.                  []   \n",
       "...                                                 ...                 ...   \n",
       "3467         Factors influencing gold bullion and efts?                  []   \n",
       "3468  Top 3 companies to invest forever goog, Micros...                  []   \n",
       "3469                        If i sell stock in ROTH IRA                  []   \n",
       "3470      Broker company question, does it even matter?                  []   \n",
       "3471                 ATER STOCK ANY THOUGHTS LOOKS GOOD                  []   \n",
       "\n",
       "      ... media_metadata.7brf4hj4zpne1.s.u  media_metadata.7brf4hj4zpne1.id  \\\n",
       "0     ...                              NaN                              NaN   \n",
       "1     ...                              NaN                              NaN   \n",
       "2     ...                              NaN                              NaN   \n",
       "3     ...                              NaN                              NaN   \n",
       "4     ...                              NaN                              NaN   \n",
       "...   ...                              ...                              ...   \n",
       "3467  ...                              NaN                              NaN   \n",
       "3468  ...                              NaN                              NaN   \n",
       "3469  ...                              NaN                              NaN   \n",
       "3470  ...                              NaN                              NaN   \n",
       "3471  ...                              NaN                              NaN   \n",
       "\n",
       "      media_metadata.w06y0kg3zpne1.status media_metadata.w06y0kg3zpne1.e  \\\n",
       "0                                     NaN                            NaN   \n",
       "1                                     NaN                            NaN   \n",
       "2                                     NaN                            NaN   \n",
       "3                                     NaN                            NaN   \n",
       "4                                     NaN                            NaN   \n",
       "...                                   ...                            ...   \n",
       "3467                                  NaN                            NaN   \n",
       "3468                                  NaN                            NaN   \n",
       "3469                                  NaN                            NaN   \n",
       "3470                                  NaN                            NaN   \n",
       "3471                                  NaN                            NaN   \n",
       "\n",
       "      media_metadata.w06y0kg3zpne1.m media_metadata.w06y0kg3zpne1.p  \\\n",
       "0                                NaN                            NaN   \n",
       "1                                NaN                            NaN   \n",
       "2                                NaN                            NaN   \n",
       "3                                NaN                            NaN   \n",
       "4                                NaN                            NaN   \n",
       "...                              ...                            ...   \n",
       "3467                             NaN                            NaN   \n",
       "3468                             NaN                            NaN   \n",
       "3469                             NaN                            NaN   \n",
       "3470                             NaN                            NaN   \n",
       "3471                             NaN                            NaN   \n",
       "\n",
       "      media_metadata.w06y0kg3zpne1.s.y media_metadata.w06y0kg3zpne1.s.x  \\\n",
       "0                                  NaN                              NaN   \n",
       "1                                  NaN                              NaN   \n",
       "2                                  NaN                              NaN   \n",
       "3                                  NaN                              NaN   \n",
       "4                                  NaN                              NaN   \n",
       "...                                ...                              ...   \n",
       "3467                               NaN                              NaN   \n",
       "3468                               NaN                              NaN   \n",
       "3469                               NaN                              NaN   \n",
       "3470                               NaN                              NaN   \n",
       "3471                               NaN                              NaN   \n",
       "\n",
       "      media_metadata.w06y0kg3zpne1.s.u media_metadata.w06y0kg3zpne1.id  \n",
       "0                                  NaN                             NaN  \n",
       "1                                  NaN                             NaN  \n",
       "2                                  NaN                             NaN  \n",
       "3                                  NaN                             NaN  \n",
       "4                                  NaN                             NaN  \n",
       "...                                ...                             ...  \n",
       "3467                               NaN                             NaN  \n",
       "3468                               NaN                             NaN  \n",
       "3469                               NaN                             NaN  \n",
       "3470                               NaN                             NaN  \n",
       "3471                               NaN                             NaN  \n",
       "\n",
       "[3472 rows x 7700 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_post_df = pd.json_normalize(posts_list)\n",
    "\n",
    "normalised_post_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets now filter this into a dataframe with only the relevant columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we include subreddit since we need it for the fetch later\n",
    "final_post_data_df = normalised_post_df[['id','subreddit_id','title', 'author', 'created_utc', 'score', 'upvote_ratio', 'num_comments', 'ups', 'subreddit', 'name']]\n",
    "\n",
    "final_post_data_df = final_post_data_df.rename(columns={'name': 'post_id'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```fetch_comments_from_post``` function below has similar functionality to the ```fetch_recent_posts``` function, using the ```after``` parameter for pagination. However, it takes in a row of a data frame instead of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited! Retrying after 5 seconds...\n",
      "Rate limited! Retrying after 25 seconds...\n",
      "Rate limited! Retrying after 125 seconds...\n",
      "Rate limited! Retrying after 5 seconds...\n",
      "Rate limited! Retrying after 25 seconds...\n",
      "Rate limited! Retrying after 125 seconds...\n",
      "Rate limited! Retrying after 625 seconds...\n"
     ]
    }
   ],
   "source": [
    "# Apply the fetch comments function to each row in the DataFrame taking headers as an input\n",
    "\n",
    "initial_comments =  final_post_data_df.apply(fetch_comments_from_post, headers=headers, axis=1);\n",
    "\n",
    "\n",
    "# flatten the list of lists returned\n",
    "\n",
    "some_comments = [comment for comments in initial_comments for comment in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62472"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some_comments[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspecting the list of dictionaries ```sum_comments```, we find that after going into the ```replies``` key of the orginal comment, and consequently going into ```data``` and then ```children``` we can access replies to a root comment. This process repeats for each comment. The function ```extract_comments``` below uses recursion, a processes that I learnt about in the Harvard CS50 online course. Every time it comes across a reply within a comment, it calls itself, taking that reply as an argument and looking for replies within it until there are no more left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_comments = [comment for comment in extract_comments(some_comments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>ups</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml1y867</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "      <td>t2_4gezv939</td>\n",
       "      <td>1.743614e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>Tariffs can always be reversed</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml1wzpj</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "      <td>t2_k9rq6iij0</td>\n",
       "      <td>1.743614e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>Already priced in. We won’t know the full econ...</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml1xmqv</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "      <td>t2_11sc4n</td>\n",
       "      <td>1.743614e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;gt; Already priced in\\n\\n&amp;gt; We won’t know t...</td>\n",
       "      <td>1</td>\n",
       "      <td>t1_ml1wzpj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml1xd06</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "      <td>t2_2snajx0o</td>\n",
       "      <td>1.743614e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>Wait till we get a partial Treasury default on...</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml1y9qw</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "      <td>t2_4r22p8do</td>\n",
       "      <td>1.743614e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember when reddit would vehemently fight ...</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_1jpttjo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151402</th>\n",
       "      <td>mfu688r</td>\n",
       "      <td>t3_1j17uuc</td>\n",
       "      <td>t2_dvy2u</td>\n",
       "      <td>1.741033e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>Fidelity and vanguard also route orders to mar...</td>\n",
       "      <td>1</td>\n",
       "      <td>t1_mflq7zs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151403</th>\n",
       "      <td>mfh4z1c</td>\n",
       "      <td>t3_1j16jd4</td>\n",
       "      <td>t2_4tx3lxsw</td>\n",
       "      <td>1.740855e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>It's a tiny company that markets random home g...</td>\n",
       "      <td>5</td>\n",
       "      <td>t3_1j16jd4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151404</th>\n",
       "      <td>mfh5er6</td>\n",
       "      <td>t3_1j16jd4</td>\n",
       "      <td>t2_1hpcjzd4db</td>\n",
       "      <td>1.740856e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>They have positive revenue and cash in hand</td>\n",
       "      <td>1</td>\n",
       "      <td>t1_mfh4z1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151405</th>\n",
       "      <td>mfha55q</td>\n",
       "      <td>t3_1j16jd4</td>\n",
       "      <td>t2_4tx3lxsw</td>\n",
       "      <td>1.740857e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>All companies have positive revenue. What do y...</td>\n",
       "      <td>3</td>\n",
       "      <td>t1_mfh5er6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151406</th>\n",
       "      <td>mficzmt</td>\n",
       "      <td>t3_1j16jd4</td>\n",
       "      <td>t2_pnavzoewb</td>\n",
       "      <td>1.740869e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>Sorry but that is the squatty potty of these s...</td>\n",
       "      <td>2</td>\n",
       "      <td>t3_1j16jd4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151407 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment_id     post_id         author   created_utc  score  \\\n",
       "0         ml1y867  t3_1jpttjo    t2_4gezv939  1.743614e+09      1   \n",
       "1         ml1wzpj  t3_1jpttjo   t2_k9rq6iij0  1.743614e+09      1   \n",
       "2         ml1xmqv  t3_1jpttjo      t2_11sc4n  1.743614e+09      1   \n",
       "3         ml1xd06  t3_1jpttjo    t2_2snajx0o  1.743614e+09      1   \n",
       "4         ml1y9qw  t3_1jpttjo    t2_4r22p8do  1.743614e+09      1   \n",
       "...           ...         ...            ...           ...    ...   \n",
       "151402    mfu688r  t3_1j17uuc       t2_dvy2u  1.741033e+09      1   \n",
       "151403    mfh4z1c  t3_1j16jd4    t2_4tx3lxsw  1.740855e+09      5   \n",
       "151404    mfh5er6  t3_1j16jd4  t2_1hpcjzd4db  1.740856e+09      1   \n",
       "151405    mfha55q  t3_1j16jd4    t2_4tx3lxsw  1.740857e+09      3   \n",
       "151406    mficzmt  t3_1j16jd4   t2_pnavzoewb  1.740869e+09      2   \n",
       "\n",
       "                                                     body  ups   parent_id  \n",
       "0                          Tariffs can always be reversed    1  t3_1jpttjo  \n",
       "1       Already priced in. We won’t know the full econ...    1  t3_1jpttjo  \n",
       "2       &gt; Already priced in\\n\\n&gt; We won’t know t...    1  t1_ml1wzpj  \n",
       "3       Wait till we get a partial Treasury default on...    1  t3_1jpttjo  \n",
       "4       I remember when reddit would vehemently fight ...    1  t3_1jpttjo  \n",
       "...                                                   ...  ...         ...  \n",
       "151402  Fidelity and vanguard also route orders to mar...    1  t1_mflq7zs  \n",
       "151403  It's a tiny company that markets random home g...    5  t3_1j16jd4  \n",
       "151404        They have positive revenue and cash in hand    1  t1_mfh4z1c  \n",
       "151405  All companies have positive revenue. What do y...    3  t1_mfh5er6  \n",
       "151406  Sorry but that is the squatty potty of these s...    2  t3_1j16jd4  \n",
       "\n",
       "[151407 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_comments_df = pd.DataFrame(final_comments)\n",
    "final_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping Dataframes into SQLite Database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we will dump our dataframes into tables that match their current structure\n",
    "- they will be mapped according to the specifications outlined, using primary and secondary keys\n",
    "- Our database engine is set up in ```utils.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subreddits Table\n",
    "| Column Name    | Data Type    | Reasoning                                                                                                                                               |\n",
    "|----------------|--------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| subreddit_id   | CHAR(8)      | characters are fixed at 8 for the subreddit ID, to ensure consistent length and efficient storage for the ID.          |\n",
    "| name           | VARCHAR(20)  | a variable length string for the subreddit name capped at 20, sufficient for most subreddit names.                 |\n",
    "| subscribers    | INTEGER      | the number of subscribers will always be a whole number              |\n",
    "| created_utc    | INTEGER      | time in UTC is an integer            |\n",
    "| description    | VARCHAR(200) | A variable length string for the subreddit’s description capped at 200            |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_text = \"\"\"\n",
    "    subreddit_id CHAR(8) PRIMARY KEY,\n",
    "    name VARCHAR(20),\n",
    "    subscribers INTEGER,\n",
    "    created_utc INTEGER,\n",
    "    description VARCHAR(200)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posts Table\n",
    "| Column Name    | Data Type    | Reasoning                                                                                                 |\n",
    "|----------------|--------------|-----------------------------------------------------------------------------------------------------------|\n",
    "| post_id        | CHAR(10)     | Unique post ID, fixed-length for efficient lookups.                                                      |\n",
    "| subreddit_id   | CHAR(8)      | ID linking post to its subreddit.                                                                        |\n",
    "| title          | VARCHAR(600) | Post title, capped for consistency and storage efficiency.                                               |\n",
    "| author         | VARCHAR(50)  | Reddit username or ID of the author.                                                                     |\n",
    "| created_utc    | INTEGER      | Unix timestamp for sorting and filtering.                                                                |\n",
    "| score          | INTEGER      | Net score (upvotes − downvotes).                                                                         |\n",
    "| upvote_ratio   | FLOAT        | Proportion of upvotes to total votes.                                                                    |\n",
    "| num_comments   | INTEGER      | Number of comments on the post.                                                                          |\n",
    "| ups            | INTEGER      | Raw upvotes (not net score).                                                                             |\n",
    "| subreddit      | VARCHAR(20)  | Subreddit name, stored for quick access without needing a join.                                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_text = \"\"\"\n",
    "    post_id CHAR(10) PRIMARY KEY,\n",
    "    subreddit_id CHAR(8),\n",
    "    title VARCHAR(600),\n",
    "    author VARCHAR(50),\n",
    "    created_utc INTEGER,\n",
    "    score INTEGER,\n",
    "    upvote_ratio FLOAT,\n",
    "    num_comments INTEGER,\n",
    "    ups INTEGER,\n",
    "    subreddit VARCHAR(20),\n",
    "    FOREIGN KEY (subreddit_id) REFERENCES subreddits(subreddit_id)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments Table\n",
    "| Column Name    | Data Type    | Reasoning                                                                                                                                               |\n",
    "|----------------|--------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| comment_id     | CHAR(6)      | fixed-length string for the comment ID, ensuring consistency and efficient lookups.       |\n",
    "| post_id        | CHAR(10)     | fixed-length string for the post ID, linking the comment to its post.        |\n",
    "| author         | VARCHAR(20)  | variable-length string for the comment's author, capped at 20 for typical username lengths.     |\n",
    "| created_utc    | INTEGER      | timestamp stored as an integer in UTC (Unix epoch time) for sorting and filtering.                    |\n",
    "| score          | INTEGER      | integer to store the comment's score (upvotes minus downvotes), representing a whole number.                                      |\n",
    "| body           | VARCHAR(40000)| variable-length string to store the comment body, capped at 40,000 for larger comments.   |\n",
    "| ups            | INTEGER      | integer to store the number of upvotes, a simple whole number useful for ranking comments.                  |\n",
    "| parent_id      | CHAR(10)     | fixed-length string to store the parent comment ID (if any), for comment threads. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_text = \"\"\"\n",
    "    comment_id CHAR(6) PRIMARY KEY,\n",
    "    post_id CHAR(10),  \n",
    "    author VARCHAR(20),\n",
    "    created_utc INTEGER,\n",
    "    score INTEGER,\n",
    "    body VARCHAR(40000),\n",
    "    ups INTEGER,\n",
    "    parent_id CHAR(10),\n",
    "    FOREIGN KEY (post_id) REFERENCES posts(post_id)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use create_table, a function outlined in ```utils.py``` which takes in two strings as arguments, one as a table title, and another as the SQL code to create the table as per our requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table('subreddits', subreddits_text)\n",
    "create_table('posts', posts_text)\n",
    "create_table('comments', comments_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use method='multi' since it sends multiple rows per query instead of one row at a time, however, this increases RAM usage for large data sets, so we we do it groups of 100 using the chunksize argument as a good midpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151407"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_comments_df.to_sql('comments', engine, if_exists='append', index=False, chunksize=100, method='multi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3472"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_post_data_df.drop(columns='id').to_sql('posts', engine, if_exists='append', index=False, chunksize=100, method='multi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sub_df.to_sql('subreddits', engine, if_exists='append', index=False, chunksize=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "+ We will access the ```database.db``` file in the exploratory data analysis notebook to continue the investigation. We will begin by querying the database to understand the data. Next we will reshape and analyse the data to gain some insights into our research question. The analysis will be supported by visualizations to help interpret and present the results effectively. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
